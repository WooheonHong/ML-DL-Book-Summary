# Part Ⅲ Classification Models

# Ch11. Measuring Performance in Classification Models

- positive predicted value

$$PPV = \frac{Sensitivity × Prevalence}{(Sensitivity × Prevalence) + ((1 - Specificity) × (1 - Prevalence))}$$

- negative predicted value

$$PPV = \frac{Sensitivity × ( 1-  Prevalence)}{((1 - Sensitivity) × Prevalence) + ((Specificity) × (1 - Prevalence))}$$

예측값은 모델 성격을 정의하는 데는 보통 쓰이지 않는다. 많은 경우, 이는 출형 정도와 관련이 있는데, 여기에는 몇 가지 이유가 있다. 우선, 출현 정도는 계량하기 어렵다. 우리가 경헝할 수 있느 것은 매우 적은 사람에 대한 것이고, 전문가라 하더라도 사전 지식에 따른 이런 수량을 추정한다. 또한 출현 정도는 동적으로 나타난다. 

AUC를 사용해 모델을 평가할 때의 단점은 정보를 찾을 수 없다는 것이다. 예를 들어, 모델 비교 시 단독 ROC 곡선이 다른 곡선보다 항상 우수하지는 않다(곡선 교차 등이 발생한다). 이 곡선에 대한 내용을 요약해보면, 곡선의 어느 특정 부분에 집중해보는 경우, 더욱 정보의 손실이 발생한다. 예를 들어, 왼쪽을 보면 한 모델이 매우 가파를 ROC 곡선을 그리지만, 다른 모델에 비해 AUC는 낮다. ROC 곡선의 낮은 쪽 끝이 원래 계획에 맞다고 해도  AUC값을 봤을 때 최적의 모델은 아니다. 곡선의 일부 부분만을 확인하려면 ROC곡선 하단의 일부 영역을 사용할 수도 있다. 

# Ch12. Discriminant Analysis and Other Linear Classification Models

클래스 불균형은 많은 변수가 분산이 0에 가까운 변수로 분류될 수 있다. 이것은 모델상의 연산 문제를 야기한다. 하지만 모든 모델에서 이런 문제가 발생하는 것은 아니므로 모델에 따라 2개의 서로 다른 예측 변수 세트를 사용하자. 예측 변수의 "전체 세트"는 분포와 상관없이 모든 변수를 사용한다. "일부 세트"는 분포가 드문드문 있는 형태를 보이거나 불균형한 예측 변수에 민감한 모델에 사용할 용도로 252개의 예측 변수를 갖는다. 결과값과의 연관 관계를 파악하지 않고 예측 변수를 제거하는 과정을 비지도 특징 선택이라고 한다. 

## Logistic Regression

## Linear Discriminant Analysis

LDA는 예측변수보다 최소 샘플 수가 5~10배 많은 경우에 적용하자. 

## Partial Least Squares Discriminant Analysis

응답 변수에 대한 정보가 거의 없거나 아예 없는 예측 변수를 포함시키면 PLS 모델 성능이 떨어진다. 

## Penalized Models

- elasticnet
- LDA모델에 FDA체계 적용

## Nearest Shrunken Centorids

최근접 축소 중심 모델(predictive analysis for microarrays, PAM)은 고차원 문제에 최적화된 선형 분류 모델이다. 

# Ch13. Nonlinear Classification Models

## Nonlinear Discriminant Analysis

선형 판별 분석은 모델이 총오분류 비율을 감소하는 방향으로 구성됐다. 각 클래스의 예측 변수는 동일한 공분산 구조를 공유한다느 가정을 통해 클래스의 경계를 예측 변수의 선형 함수 형태로 만든다. 

이차 판별 모델의 경우, 이 가정이 느슨하게 적용돼 클래스별 공분산 구조를 포함할 수 있다. 이 변화에 따른 가장 큰 파급 효과는 이제 의사 결정의 경계가 예측 변수 공간 내의 2차 곡선으로 변한다는 것이다. 판별 함수의 복잡도가 증가하면, 많은 문제의 경우 모델 성능이 향상되기도 한다. 하지만 이런 일반화의 다른 파급 효과는 데이터의 정의가 보다 엄격해진다는 것이다. 클래스별 공분산 행렬을 사용하는 경우에는 역행렬이 존재해야 한다. 즉, 변수 수는 각 클래스 내 경우의 수보다 적어야 한다. 또한 각 클래스 내의 변수는 극단적인 공선성을 가지면 안된다. 게다가 데이터의 주요 변수가 이산 범주형인 경우, QDA에서만 이를 선형 함수 형태로 모델링할 수 있고, 이마저도 모델의 효과는 제한된다.

선형와 이차 클래스 경계 사이 어딘가의 형태에서 잘 구분될 수 있다. RDA는 LDA와 QDA사이의 평면을 연결하는 하나의 방식이다. 

LDA의 확장 형태로 MDA를 개발했다. LDA에서는 클래스별 평균이 각각 다른 예측 변수 데이터에 대한 분포를 가정하고 있다(이때 공분산 구조는 클래스 독립적이다). MDA에서는 LDA를 다른 관점에서 일반화한다. 여기서는 각 클래스가 여러 다변량 정규 분포를 따르는 것을 허용한다. 이 분포의 평균은 각각 다르겠지만, 공분산 구조는 LDA와 마찬가지로 동일하게 가정한다. 

## Neural Networks

엔트로피 함수가 오차 제곱 항 함수로 만들어진 값보다 작은 확률값을 정확하게 추정한다. 

## Flexible Discriminant Analysis

1. 각 C개의 클래스에 대한 이진 가변수를 열로 하는 새로운 응답 변수 행렬을 만든다.
2. 예측 변수나 예측 변수의 함수에 대한 기울기와 절편을 구하는 다변량 회귀 모델을 만든다(선형 회귀, MARS등 어느 방법을 사용해도 된다.).
3. 최적 점수화 깁버을 사용해 모델 변수 후처리를 한다.
4. 가법 회귀 계수를 판별값으로 사용한다.

MARS나 FDA배깅 모델은 모델 성능에 미치는 영향이 미미할 뿐만 아니라 항의 수가 증가할수록 판별 방정식의 해석력이 감소한다. 

## Support Vector Machines

축소 데이터 세트에서 성능이 더 좋다.

## K-Nearest Neighbors

## Naive Bayes

나이브 베이즈 모델은 모든 예측 변수가 상호 독립적이라는 가정하에 예측 변수값의 확률 계산을 단순화한다. 이 독립 가정은 계산 복잡도를 눈에 띄게 감소시켜준다. 

연속형 변수에 대해서는 정규분포를 가정한다. 범주형 변수의 경우, 훈련 데이터 세트의 관측 빈도를 사용해 확률 분포를 파악할 수 있다. 

나이브 베이즈 모델은 큰 훈련 데이터 세트에서도 빠르게 구할 수 있다. 둘째, 이런 엄격한 가정에도 불구하고, 많은 경우 모델 성능이 괜찮은 편이다. 

새 샘플 값을 예측할 때, 모델에서 만든 클래스별 확률값을 베이즈 규칙을 사용해 보정한다. 얄궃게도, 일반적으로 베이즈 규칙을 적용해 구한 클래스 확률은 잘 보정되지 않은 경향이 있다. 예측 변수 수가(샘플 크기에 비해 상대적으로) 늘어날수록 사후 확률은 보다 극단적으로 움직인다. 

# Ch14. Classification Trees and Rule-Based Models

## Basic Classification Trees

분류 트리의 목적은 데이터를 보다 작고 동질적인 그룹으로 분할하는 것이다. 여기서 동질성이란, 분기별 노드가 보다 순수한 성격을 갖는 것이다(각 노드에는 동일한 클래스의 비율이 높은 것). 분류에서 순수를 정의하는 간단한 방법은 정확도를 높이거나 오뷴류를 낮추는 것이다. 그러나 순수 척도로서의 정확도를 사용하면 샘플을 주로 한 클래스로 분류하는 방식으로 데이터를 분할하는 것보다는 오분류를 최소화하는 방식으로 데이터를 분할하는 것에 초점을 두게 되므로 다소 그릇된 방향으로 나아갈 수 있다. 

이에 대한 두 가지 대안으로 지니 계수와 교차 엔트로피가 있다. 

분할 알고리즘에서는 거의 모든 분기점에 대해 구한 후 순도 수치를 최소화하는 분기값을 선택한다.

트리 구축 시 분기를 생성하는 경우에는 결측 정보가 없는 샘플만을 사용한다. 예측 시에는 결측값이 있는 분기에 대해서는 다른 분기점을 사용한다. 이와 비슷한 방식으로 각 예측 변수에 대한 최적화 기준에 따른 전체 반영도를 구해 분류 트리에서의 변수 중요도를 구할 수 있다. 

개별 범주를 사용한 트리가 그룹범주를 사용한 트리보다 훨씬 해석하기가 쉽다. 

c4.5모델은 정보 이론을 따라 분기 기준을 만든다. 

# Ch15. A Summary of Grant Application Models

부트스트랩을 사용해 구한 95% 신뢰구간

1. 모델 사용자들이 이 구간을 보면서 모델이 어느 정도 좋고, 나쁜지를 판단할 수 있다. 이 구간은 모델 변량을 수량화할 뿐만 아니라 데이터 자체를 반영하기도 한다. 예를 들어, 응답 세트가 작거나 잡음(또는 답이 잘못 매겨진 경우)이 있는 경우 구간이 넓어질 것이다.

    이 경우, 신뢰 구간을 통해 모델 비교 시에 사용할 수 있는 가중값을 측정할 수 있다. 

2. 모델 간 트레이드 오프가 가능하다. 두 모델의 신뢰 구간이 많이 겹쳐지는 경우, 두 모델이 (통계적으로) 유사하며 이런 경우, 덜 복잡하거나 더 해석력이 좋은 모델을 선택할 수 있다.

![Part%20%E2%85%A2%20Classification%20Models%20254c22de85914cbaba93a355a6e70c3b/Untitled.png](Part%20%E2%85%A2%20Classification%20Models%20254c22de85914cbaba93a355a6e70c3b/Untitled.png)

Fig 15.2: A plot of the test set ROC curve AUCs and their associated 95% confidence intervals

# Ch16. Remedies for Serve Class Imbalance

## Model Tuning

클래스 불균형의 부정적 영향에 대처하기 위한 가장 단순한 방법은 적은 클래스의 정확도를 최대화하도록 모델을 튜닝하는 것이다. 

## Alternate Cutoffs

두 가능한 결과 범주의 경우, 적은 클래스 샘플의 예측 정확도를 증가시키기 위한 또 다른 방법으로는 예측 사건의 정의를 효과적으로 변경해줄 수 있는 예측 확률의 대체 한도 지정을 들 수 있다. 

새로운 한도를 판단하는 데에는 여러 가지 방법이 있다. 첫 번째 방법은 민감도나 특이도를 충족시켜야 하는 특정 표적이 있는 경우, 이 점을 ROC 곡선에서 찾아내는 방법이다. 이에 따라 해당 한도를 결정할 수 있다. 또 다른 방법은 그래프 상단의 최적 모델(100% 민감도와 100% 특이도)에 가장 가까운(거리가 가장 짧은) ROC 곡선을 찾는 방법이다. 한도를 판단하는 다른 방법으로는 사건 그룹과 사건이 일어나지 않은 그룹 양쪽에서 제대로 예측된 샘플의 비율을 구하는 요든의 J지수가 있다. 이 지수를 사용해 ROC 곡선을 만드는 데 사용하는 한계를 구할 수도 있다.

이 분석에서 모델의 대체 한도는 훈련 데이터 세트나 테스트 데이터 세트로부터 유도하지 않는다. 샘플 사이즈가 작은 경우, 특히 대체 한도를 유도하기 위해 다른 데이터 세트를 사용해야 한다는 것을 반드시 알아둬야 한다. 훈련 데이터 세트 예측 시 클래스 확률에 편향성이 있는 경우, 민감도와 특이도를 부정확하게 측정한다. 테스트 세트를 사용하는 경우, 모델 성능을 판단할 편향적이지 않은 데이터가 없어진다. 

## Adjusting Prior Probabilities

나이브 베이즈나 판별 분석 분류기 같은 모델들에서는 사전 확률을 사용한다.

모델을 바꾸는 것은 아니지만, 민감도와 특이도 간의 다른 트레이드 오프가 가능하다.

## Unequal Case Weights

많은 분류 예측 모델에서는 모델 훈련 단계에서 각 개별 데이터가 강조되는 경우, 각 경우별 가중값을 사용할 수 있다. 예를 들어, 앞에서 논의한 부스팅 분류 방법이나 회귀 트리는 연속적 모델들을 만들 수 있는데, 이 모델들은 각 반복 시에 서로 다른 경우별 가중값을 사용한다. 

## Sampling Methods

데이터상의 클래스 불균형에 대한 사전 지식이 있다면, 모델 훈련 시에 이로 인한 영향을 감소시킬 수 있는 직관적 방법으로 초기 데이터 수집 시 대략 동일한 사건 비율로 훈련 데이터 세트 샘플을 선택하는 방법이 있다는 것을 알고 있을 것이다. 기본적으로 불균형을 처리하는 모델을 만드는 대신, 클래스 빈도를 균형 있게 만들 수 있다. 이 방법을 사용함으로써 모델 훈련을 어렵게 만들었던 기본적인 불균형 문제를 제거한다. 하지만 만약 훈련 데이터 세트가 균형 있게 샘플링됐다면, 테스트 데이터 세트는 보다 자연스럽게 샘플링돼서 불균형 상태를 반영할 수 있어야 이후에 제대로 된 성능 추정값을 구할 수 있을 것이다. 

만약, 사전 샘플링 방식을 사용할 수 없다면, 모델 훈련 시의 불균형으로 인한 효과를 약화시킬 수 있는 사후 샘플링 방식을 사용할 수 있다. 

램덤 포레스트에 대한 구현에서는 본질적으로 부트스트랩 샘플링 과정을 층화 변수를 통해 조절하는 다운 샘플링 방식을 사용한다. 만약, 클래스를 층화 변수로 사용한다면, 부트스트랩 샘플을 클래스별 동일한 크기로 만들 수 있을 것이다. 여기서는 훈련 데이터 세트를 내부적으로 다운 샘플링한 후 이를 앙상블 트리를 만드는 데 사용한다. 

synthetic minority oversampling technique(SMOTE)은 업 샘플링과 다운 샘플링을 모두 사용하느 데이터 샘플링 과정으로, 이 방법은 클래스 의존적이고 업 샘플링 양, 다운 샘플링 양, 새로운 경우에 대해 대치값으로 사용할 이웃 데이터 수, 즉 3개 인수를 갖는다. 소수 클래스를 업 샘플링 할 때는 SMOTE에서 새 경우를 합성한다. 이때 임의로 소수 클래스에서 데이터를 선택한 후, 이 데이터의 KNN을 구한다. 새로 합성된 데이터 값은 임의로 선택된 데이터와 이 이웃 데이터의 변수에 대한 임의의 조합을 통해 나온 값이다. SMOTE 알고리즘에서 업 샘플링을 통해 소수 클래스에 새 샘플을 추가함과 동시에 훈련 데이터 세트의 균형을 위한 랜덤 샘플링으로 주 클래스에서는 다운 샘플링을 수행한다. 

훈련 데이터 세트를 수정한 버전을 사용할 때, 모델 성능의 리샘플링 추정값은 편향 될 수 있다는 것을 염두에 둬야 한다. 

## Cost-Sensitive Training

몇몇 모델에서는 정확도나 비순도 같은 일반적인 성능 지표를 최적화하는 대신, 특정 오차에 다른 가중값을 줘 비용이나 손실 함수를 최적화하는 방식을 사용할 수 있다. 예를 들어, 실제 사건이 발생한 건을 오분류한 경우(false positive), 사건이 일어나지 않을 것을 잘못 분류한 것(false negative)의 X배 비용이 든다고 믿을 수 있다. 모델 훈련에서 특정 비용을 합치는 경우, 빈도가 낮은 클래스 쪽으로 모델을 이동시킬 수 있다. 차등 비용을 부과하는 것은 대체 한도를 사용하는 것과 달리, 모델 인수에 영향을 미치게 되므로 분류기에 실질적인 향상을 미칠 수 있다.

비용은 SVM 모델에서 (특정 오류 유형이 아닌) 특정 클래스와 관련이 있다. 이 모델은 샘플이 현재 클래스 경계의 잘못된 쪽에 들어 있는 경우, 벌점을 부과하는 식의 비용 함수를 통해 복잡도를 조절한다는 점을 상기하자. 클래스 불균형에서 각 클래스에 대해 차등 비용을 부과함으로써 인수를 각각의 클래스에 대한 모델의 민감도가 증가하거나 감소하도록 조정할 수 있다. 이 방법은 특정 유형의 오류에 다른 비용을 부과하는 것과는 다르다는 것을 기억하자. 

이 방법의 한 가지 결과는 최소한 가능한 구현 방법으로는 모델에서 클래스 확률을 구할 수 없다는 것이다. 따라서 ROC 곡선도 구할 수 없으므로 다른 성능 지표를 사용해야 한다. 그래서 대신 카파 통계량, 민감도, 특이도를 사용해 가중값 효과를 평가한다. 

추가로  CART와 C5.0 트리를 포함하는 많은 분류 트레 모델은 서로 다른 비용을 사용하는 것을 고려할 수 있다. 예측에 필요한 비용은 여러 측면을 고려할 수 있다. 

- 개별 실수에 대한 비용
- 실수가 발생할 확률
- 클래스별 사전 확률

$$\begin{aligned} Gini &= C(1|2)p_1(1 - p_1) + C(2|1)p_2(1 - p_2) \\ &= [C(1|2) + C(2|1)]p_1p_2\end{aligned}$$

2개 이상의 클래스를 사용할 때는 지니 계수 행렬을 적용햐면 비용이 대칭화된다. 즉, 분기의 전체 비용을 구할 때는 $C(i|j)$와 $C(j|i)$의 평균을 낸다.

비용 민감 트리가 명목형 과정을 통해 만들어진 트리보다 작아지는 경향이 있다고 명시했다. 그 이유는 트리 성장 단계에서 트리가 비용이 높을 수 있는 오차에 대해서는 정확히 예측하지만, 보다 비용이 적은 오차에 대해서는 별로 정확하지 않은 방향으로 분기가 이뤄지기 때문이다.

트리(와 규칙)의 경우, 예측 클래스 확률(이나 신뢰도 값)에 서로 다른 비용이 사용된 클래스 예측에 있어서는 일관적이지 않을 수도 있다. 샘플의 최종 클래스 예측은 클래스 확률과 비용 구조로 이뤄진 함수다. 앞에서 살펴본 것처럼 말단 노드에서의 클래스 확률은 하나의 클래스를 나타내는 식이 되는 경우가 많지만, 이에 대한 기대 비용이 커질수도 있다. 이런 연유로 신뢰값과 예측 클래스 간에 단절이 생긴다. 따라서 이런 경우에는 단순 클래스 확률을 사용하면 안된다. 

![Part%20%E2%85%A2%20Classification%20Models%20254c22de85914cbaba93a355a6e70c3b/Untitled%201.png](Part%20%E2%85%A2%20Classification%20Models%20254c22de85914cbaba93a355a6e70c3b/Untitled%201.png)

Fig 16.6 Tuning results for cost-sensitive classification tree models determined with cross-validation and the evaluation set

비용 민감 모델 훈련을 확인해보기 위해 이전의 가중값을 적용한 SVM 모델과 비슷한 방식으로 동일한 비용뿐만 아니라 다양한 비용 범위를 사용해 단일 CART트리를 데이터에 적용해봤다. Fig 16.6은 훈련 데이터 및 평가 데이터로부터 나온 결과다. 이 그림의 추세상으로는 잡음이 많아 보인다(CART 트리의 불안정성 때문). 특히, 샘플 크기가 더 작은 경우의 민감도에 대해서는 더 잡음이 심하다.

민감도의 리샘플링 추정값은 평가 데이터 세트보다 더 비관적이다. 이 결과에서 모델의 민감도와 특이도가 높은 비용값에서 수렴하기 시작하는 것을 확인할 수 있다. 

C5.0에서는 분기에 지니 계수를 사용하지 않는다는 것을 상기해보자. 비용을 사용할 때는 이전의 식을 사용하되 사전 확률이 동일하다고 가정한다. 새 샘플은 가장 낮은 비용의 클래스로 예측되는 것을 다시 볼 수 있다.

![Part%20%E2%85%A2%20Classification%20Models%20254c22de85914cbaba93a355a6e70c3b/Untitled%202.png](Part%20%E2%85%A2%20Classification%20Models%20254c22de85914cbaba93a355a6e70c3b/Untitled%202.png)

Fig. 16.7: Performance profiles for C5.0 models using cost-sensitive learning

C5.0의 경우, 모델 유형(트리, 규칙 기반 등)과 부스팅 반복 횟수에 맞게 튜닝해야 한다. Fig 16.7은 5부터 50까지의 범위에 대한 부정 오류 비용에 대해 비용 민감 학습 패턴을 나타낸 것이다. SVM 분석과 마찬가지로 훈련 데이터 세트와 평가 세트에 대해 일정한 곡선이 나타났다. 카파 통계량을 통해 일치 정도를 최적화하면, 작은 비용값을 사용해야 하고, 민감도를 증가시키고 많은 비용이 드는 경우에는 완화해야 할 필요가 있다. 여기서는 민감도와 특이도 간의 명확한 트레이드 오프가 나타나지만, 민감도의 경우 비용이 25나 30 정도로 커지면 변화가 정체됨을 알 수 있다. 

# Ch17. Case Study: Job Scheduling