# Ch6~Ch11

# Ch6. 모델 평가와 하이퍼파라미터 튜닝의 모범 사례

## 파이프라인을 사용한 효율적인 워크플로

```python
from sklearn.preprocessing import StandardScaler
from sklearn.decomposing import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
pipe_lr = make_pipeline(StandardScaler(),
                       PCA(n_components = 2),
                       LogisticRegression(solver = 'liblinear', random_state = 1))
pipe_lr.fit(X_train, y_train)
y_pred = pipe_lr.predict(X_text)
print(f'테스트 정확도: {pipe_lr.score(X_test, y_test):.3f}')
```

make_pipeline함수는 여러 개의 사이킷런 변환기(입력에 대해 fit 메서드와 transform 메서드를 지원하는 객체)와 그 뒤에 fit 메서드와 predict 메서드를 구현한 사이킷런 추정기를 연결할 수  있습니다. 

사이킷런의 Pipeline 클래스를 meta-learner나 개별 변환기와 추정기를 감싼 wrapper로 생각할 수 있습니다. Pipeline 객체의 fit 메서드를 호출하면 데이터가 중간 단계에 있는 모든 변환기의 fit 메서드와 transform 메서드를 차례로 거쳐 추정기 객체에 도달합니다. 추정기는 변환된 훈련 세트를 사용하여 학습합니다.

파이프라인의 중간 단계 횟수는 제한이 없습니다. 파이프라인의 마지막 요소는 추정기가 되어야 합니다.

파이프라인에서 fit 메서드를 호출하는 것과 비슷하게 predict 메서드도 제공합니다. Pipeline인스턴스의 predict 메서드를 호출할 때 주입된 데이터는 중간 단계의 transform 메서드를 통과합니다. 마지막 단계에서 추정기 객체가 변환된 데이터에 대한 예측을 반환합니다.

![Ch6~Ch11%20762d96258f5c476698ddfd92024ca686/Untitled.png](Ch6~Ch11%20762d96258f5c476698ddfd92024ca686/Untitled.png)

## K-fold cross-validation을 사용한 모델 성능 평가

비교적 작은 훈련 세트로 작업한다면 폴드 개수를 늘리는 것이 좋습니다. 대규모 데이터셋으로 작업할 때는 k = 5와 같은 작은 k값을 선택해도 모델의 평균 성능을 정확하게 추정할 수 있습니다.

```python
import numpy as np
import sklearn.model_selection import StratifiedKFold

kfold = StratifiedKFold(n_splits = 10, random_state = 1).split(X_train, y_train)
scores = []
for k, (train, test) in enumerate(kfold):
    pipe_lr.fit(X_train[train], y_train[train])
    score = pipe_lr.score(X_train[test], y_train[test])
    scores.append(score)
    print(f'폴드: {k+1:2d}, 클래스 분포: {np.bincount(y_train[train])}, 정확도: {score:.3f}')
```

교차 검증에 여러 측정 지표를 사용할 수 있는 cross_validate도 존재한다. 

```python
from sklearn.model_selection import cross_validate

scores = cross_validate(estimator=pipe_lr,
                        X=X_train,
                        y=y_train,
                        scoring=['accuracy'],
                        cv=10,
                        n_jobs=-1,
                        return_train_score=False)

print(f"CV 정확도 점수: {scores['test_accuracy']}")
print(f"CV 정확도 점수: {np.mean(scores['test_accuracy']):.3f} +/- {np.std(scores['test_accuracy']):.3f}")
```

## 학습 곡선과 검증 곡선을 사용한 알고리즘 디버깅

```python
import matplotlib.pyplot as plt
%matplotlib inline
from sklearn.model_selection import learning_curve

pipe_lr = make_pipeline(StandardScaler(),
                       LogisticRegression(solver='liblinear',
                                         penalty='l2',
                                         random_state=1))
train_sizes, train_scores, test_scores = \
                learning_curve(estimator=pipe_lr,
                              X=X_train,
                              y=y_train,
                              train_sizes=np.linspace(
                              0.1, 1, 10),
                              cv=10,
                              n_jobs=1)
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

plt.plot(train_sizes, train_mean,
         color='blue', marker='o',
         markersize=5, label='training accuracy')

plt.fill_between(train_sizes,
                 train_mean + train_std,
                 train_mean - train_std,
                 alpha=0.15, color='blue')

plt.plot(train_sizes, test_mean,
         color='green', linestyle='--',
         marker='s', markersize=5,
         label='validation accuracy')

plt.fill_between(train_sizes,
                 test_mean + test_std,
                 test_mean - test_std,
                 alpha=0.15, color='green')

plt.grid()
plt.xlabel('Number of training samples')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.ylim([0.8, 1.03])
plt.tight_layout()
plt.show()
```

```python
from sklearn.model_selection import validation_curve
param_range = [0.001, 0.01, 0.1, 1, 10, 100]
train_scores, test_scores = validation_curve(
                estimator=pipe_lr,
                X=X_train,
                y=y_train,
                param_name='logisticregression__C',
                param_range=param_range,
                cv=10)
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

plt.plot(param_range, train_mean, 
         color='blue', marker='o', 
         markersize=5, label='training accuracy')

plt.fill_between(param_range, train_mean + train_std,
                 train_mean - train_std, alpha=0.15,
                 color='blue')

plt.plot(param_range, test_mean, 
         color='green', linestyle='--', 
         marker='s', markersize=5, 
         label='validation accuracy')

plt.fill_between(param_range, 
                 test_mean + test_std,
                 test_mean - test_std, 
                 alpha=0.15, color='green')

plt.grid()
plt.xscale('log')
plt.legend(loc='lower right')
plt.xlabel('Parameter C')
plt.ylabel('Accuracy')
plt.ylim([0.8, 1.00])
plt.tight_layout()
plt.show()
```

## 그리드 서치를 사용한 머신 러닝 모델 세부 튜닝

```python
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC

pipe_svc = make_pipeline(StandardScaler(),
                        SVC(random_state=1))
param_range = [0.0001, 0.001, 0.01, 0.1,
              1, 10, 100, 1000]
param_grid = [{'svc__C': param_range,
              'svc__kernel': ['linear']},
             {'svc__C': param_range,
             'svc__gamma': param_range,
             'svc__kernel': ['rbf']}]
gs = GridSearchCV(estimator=pipe_svc,
                 param_grid=param_grid,
                 scoring='accuracy',
                 cv=10,
                 n_jobs=-1)
gs = gs.fit(X_train, y_train)
print(gs.best_score_)
print(gs.best_params_)
```

GridSearchCV클래스는 교차 검증으로 최상의 매개변수 조합을 찾은 후 전체 데이터셋을 사용해서 최종 모델을 훈련하여 best_estimator_ 속성에 저장하기 때문에 best_estimator 객체를 다시 훈련시킬 필요가 없습니다. 

### 중첩 교차 검증을 사용한 알고리즘 선택

여러 종류의 머신러닝 알고리즘을 비교하려면 nested cross-validation방법이 권장됩니다. 오차 예측에 대한 편향을 연구하는 중에 바르마와 사이몬은 중첩된 교차 검증을 사용했을 때 테스트 세트에 대한 추정 오차는 거의 편향되지 않는다는 결론을 얻었습니다.

계산 성능이 중요한 대용량 데이터셋에서 유용합니다.

![Ch6~Ch11%20762d96258f5c476698ddfd92024ca686/Untitled%201.png](Ch6~Ch11%20762d96258f5c476698ddfd92024ca686/Untitled%201.png)

교차 검증 횟수가 늘어나면 반복마다 전처리 과정을 반복하는 것이 낭비입니다. 사이킷런 0.19버전에서 전처리 결과를 캐싱하여 실행 속도를 높일 수 있도록 Pipeline 클래스와 make_pipeline함수에 memory 매개변수가 추가되었습니다. memory 매개변수에 캐싱에 사용할 디렉터리 경로를 지정할 수 있습니다.

```python
gs = GridSearchCV(estimator = pipe_svc,
                 param_grid = param_grid,
                 scoring = 'accuracy',
                 cv = 2)
scores = cross_val_score(gs, X_train, y_train,
                        scoring = 'accuracy', cv = 5)
print(f'CV 정확도: {np.mean(scores):.3f} +/- {np.std(scores):.3f}')
```

## 여러 가지 성능 평가 지표

### 다중 분류의 성능 지표

$$PRE_{micro} = \frac{TP_1 + \cdots + TP_k}{TP_1 + \cdots + TP_k + FP_1 + \cdots + FP_k}$$

$$PRE_{macro} = \frac{PRE_1 + \cdots + PRE_k}{k}$$

마이크로 평균은 각 샘플이나 예측에 동일한 가중치를 부여하고자 할 때 사용합니다. 마크로 평균은 모든 클래스에 동일한 가중치를 부여하며 분류기의 전반적인 성능을 평가합니다. 이 방식에서는 가장 빈도 높은 클래스 레이블의 성능이 중요합니다. 

사이킷런에서 정규화 또는 가중치가 적용된 마크로 평균이 기본으로 적용됩니다. 가중치가 적용된 마크로 평균을 계산할 때 각 클래스 레이블의 샘플 개수를 가중하여 계산합니다. 가중치 적용된 마크로 평균은 레이블마다 샘플 개수가 다른 불균형한 클래스를 다룰 때 유용합니다. 

sklearn.metrics.classification_report 함수는 정밀도, 재현율, f1-score를 한 번에 계산하여 출력해 줍니다. 

## 불균형한 클래스 다루기

어플리케이션의 주요 관심 대상이 무엇인지에 따라 정밀도, 재현율, ROC 곡선 등을 사용할 수 있습니다. 예를 들어 추가적인 검사가 필요한 악성 종양 환자의 대부분을 구별하는 것이 가장 중요할 수 있습니다. 여기서는 재현율 지표를 선택해야 합니다. 스팸 필터의 경우 이메일이 너무 자주 스팸으로 처리되는 것을 원하지 않습니다. 여기서는 정밀도가 더 적절한 지표입니다.

머신 러닝 모델을 평가하는 것과 별개로 클래스 불균형은 모델이 훈련되는 동안 학습 알고리즘 자체에 영향을 미칩니다. 머신러닝 알고리즘이 일반적으로 훈련하는 동안 처리한 샘플에서 계산한 보상 또는 비용 함수의 합을 최적화합니다. 결정 규칙은 다수 클래스 쪽으로 편향되기 쉽습니다. 다른 말로 하면 알고리즘이 훈련 과정에서 비용을 최소화하거나 보상을 최대화하기 위해 데이터셋에서 가장 빈도가 높은 클래스의 예측을 최적화하는 모델을 학습합니다.

모델을 훈련하는 동안 불균형한 클래스를 다루는 한 가지 방법은 소수 클래스에서 발생한 예측 오류에 큰 벌칙을 부여하는 것입니다. 사이킷런에서는 대부분의 분류기에 구현된 class_weight 매개변수를 class_weight='balanced'로 설정해서 이런 벌칙을 편리하게 조정할 수 있습니다. 'balanced'로 지정하면 전체 샘플 개수 / 클래스 개수를 각 레이블의 샘플 개수로 나누어 score 점수를 가중 평균합니다. 딕셔너리를 직접 주입할 수도 있습니다. 

# Ch7. 다양한 모델을 결합한 앙상블 학습

## 앙상블 학습

**ensemble learning**의 목표는 ****여러 분류기를 하나의 메타 분류기로 연결하여 개별 분류기보다 더 좋은 일반화 성능을 달성하는 것입니다. 

이 장에서는 **majority voting**방식을 집중해서 다루겠습니다. 과반수 투표는 분류기의 과반수가 예측한 클래스 레이블을 선택하는 단순한 방법입니다. 즉, 50% 이상 투표를 받은 클래스 레이블을 선택합니다. 

![Ch6~Ch11%20762d96258f5c476698ddfd92024ca686/Untitled%202.png](Ch6~Ch11%20762d96258f5c476698ddfd92024ca686/Untitled%202.png)

$$\hat y = mode\{C_1(x), C_2(x),...,C_m(x)\}$$

## 다수결 투표를 사용한 분류 앙상블

가중치가 적용된 다수결 투표는 다음과 같이 쓸 수 있습니다.

$$\hat y = \text{arg}~\underset{i}{\text{max}}\sum^m_{j =1}w_j\chi_{A}\big(C_j(x) = i\big)$$

앙상블의 분류기가 잘 보정(calibration)되어 있다면 다수결 투표에서 클래스 레이블 대신 예측 클래스 확률을 사용하는 것이 좋습니다. 사이킷런에서는 sklearn.calibration.CalibratedClassifierCV 클래스를 사용하여 보정된 분류기를 훈련시킬 수 있습니다. 확률을 사용하여 클래스 레이블을 예측하는 다수결 투표 버전은 다음과 같이 쓸 수 있습니다.

$$\hat y = \text{arg}\underset{i}{\text{max}}\sum^m_{j = 1}w_jp_{ij}$$

여기서 $P_{ij}$는 클래스 레이블 i에 대한 j번째 분류기의 예측 확률입니다.

```python
from sklearn.base import BaseEstimator
from sklearn.base import ClassifierMixin
from sklearn.preprocessing import LabelEncoder
from sklearn.externals import six
from sklearn.base import clone
from sklearn.pipeline import _name_estimators
import numpy as np
import operator

class MajorityVoteClassifier(BaseEstimator, ClassifierMixin):
    """다수결 투표 앙상블 분류기
    
    매개변수
    ----------
    classifiers : 배열 타입, 크기 = [n_classifiers] 
     앙상블에 사용할 분류기
    
    vote : str, {'classlabel', 'probability'}
     기본값: 'classlabel'
     'classlabel'이면 예측은 다수인 클래스 레이블의 인덱스가 됩니다
     'probability'면 확률 합이 가장 큰 인덱스로 
     클래스 레이블을 예측합니다(보정된 분류기에 추천합니다)
     
    weights : 배열 타입, 크기 = [n_classifiers]
    선택 사항, 기본값: None
    'int'또는 'float'값의 리스트가 주어지면 분류기가 이 중요도로 가중치됩니다
    'weights = None'이면 동일하게 취급합니다 
    
    """
    def __init__(self, classifiers,
                vote = 'classlabel', weights = None):
        
        self.classifiers = classifiers
        self.named_classifiers = {key: value for key, value in 
                                 _name_estimators(classifiers)}
        self.vote = vote
        self.weights = weights
        
    def fit(self, X, y):
        """분류기를 학습합니다
        
        매개변수
        ----------
        X : {배열 타입, 희소 행렬},
            크기 = [n_samples, n_features]
            훈련 샘플 행렬
        
        y : 배열 타입, 크기 = [n_samples]
            타깃 클래스 레이블 벡터
            
        반환값
        -----------
        self : 객체
        
        """
        # self.predict 메서드에서 np.argmax를 호출할 때 
        # 클래스 레이블이 0부터 시작되어야 하므로 LabelEncoder를 사용합니다
        self.lablenc_ = LabelEncoder()
        self.lablenc_.fit(y)
        self.classes_ = self.lablenc_.classes_
        self.classifiers_ = []
        for clf in self.classifiers:
            fitted_clf = clone(clf).fit(X,
                                       self.lablenc_.transform(y))
            self.classifiers_.append(fitted_clf)
        return self
    
    def predict(self, X):
        """X에 대한 클래스 레이블을 예측합니다
        
        매개변수
        ---------
        X : {배열 타입, 희소 행렬},
            크기 = [n_samples, n_features]
            샘플 데이터 행렬
            
        반환값
        ---------
        maj_vote : 배열 타입, 크기 = [n_samples]
            예측된 클래스 레이블
        
        """
        if self.vote == 'probability':
            maj_vote = np.argmax(self.predict_proba(X), axis = 1)
        else: # 'classlabel' 투표
            
            # clf.predict 메서드를 사용하여 결과를 모읍니다 
            predictions = np.asarray([clf.predict(X)
                                        for clf in self.classifiers_]).T
            
            maj_vote = np.apply_along_axis(lambda x: np.argmax(np.bincount(x, weights = self.weights)),
                                          axis = 1, arr = predictions)
            
        maj_vote = self.lablenc_.inverse_transform(maj_vote)
        return maj_vote
    
    def predict_proba(self, X):
        """X에 대한 클래스 확률을 예측합니다
        
        매개변수
        ----------
        X : {배열 타입, 희소 행렬},
            크기 = [n_samples, n_features]
            n_samples는 샘플의 개수고 n_features는 특성의 개수인
            샘플 데이터 행렬
            
        반환값
        --------------
        avg_proba : 배열 타입,
            크기 = [n_samples, n_classes]
            샘플마다 가중치가 적용된 클래스의 평균 확률
            
        """
        probas = np.asarray([clf.predict_proba(X)
                            for clf in self.classifiers_])
        avg_proba = np.average(probas,
                              axis = 0, weights = self.weights)
        return avg_proba
    
    def get_params(self, deep=True):
        """GridSearch를 위해 분류기의 매개변수 이름을 반환합니다"""
        if not deep:
            return super(MajorityVoteClassifier, 
                        self).get_params(deep = False)
        else:
            out = self.named_classifiers.copy()
            for name, step in six.iteritems(self.named_classifiers):
                for key, value in six.iteritems(
                step.get_params(deep = True)):
                    out['%s__%s' % (name, key)] = value
            return out
```

- BaseEstimator클래스를 상속하여 추가적인 속성이나 메소드를 제공받습니다.BaseEstimator는 get_params와 set_params를 메서드로 가지고 있습니다. 이 메서드들은 사이킷런의 파이프라인과 그리드 탐색에 꼭 필요한 메서드입니다. 이 두 메서드는 생성자에 명시된 매개변수만을 참조하므로 __ init __함수에 *args나 **kargs를 사용해서는 안 됩니다. 그리고 오버라이딩 하지 않는 것을 추천합니다.
- ClassifierMixin클래스를 상속하여 추가적인 속성이나 메소드를 제공받습니다. 만들고자 하는 객체 타입에 따라 ClassifierMixin, RegressorMixin, ClusterMixin, TransformerMixin을 정합니다. 여기에는 예측 정확도를 계산하는 예측 정확도를 계산하는 score 메서드가 포함됩니다.
- `np.mean` vs `np.average`: `np.average`는 옵션으로 weight를 할당할 수 있습니다.
- super() vs super(자식클래스, self): 후자는 현재 클래스가 어떤 클래스인지 명확하게 표시합니다. 하지만 클래스 이름을 변경할 때 해당 코드도 함께 변경해야하고 다중상속을 사용한 경우 문제가 생깁니다.
- pipeline 모듈에 있는 `_name_estimators`함수는 추정기 객체의 리스트를 입력받아 소문자 클래스 이름과 객체로 이루어진 튜플의 리스트를 반환합니다. 클래스의 객체가 두 개 이상 있으면 소문자 클래스 이름 뒤에 '-'와 1부터 증가되는 숫자를 덧붙입니다.
- 결정 트리는 말단 노드의 클래스별 샘플 비율이 클래스 확률이 됩니다. KNN은 주어진 샘플의 최근접 이웃 클래스별 샘플 비율이 클래스 확률이 됩니다.
- `clone()`는 추정기에서 모델의 deep copy를 첨부된 데이터를 복사하지 않고 수행합니다. 아직 데이터에 fit하지 않은 동일한 파라미터를 가진 새로운 추정기를 생성합니다.

## 배깅: 부트스트랩 샘플링을 통한 분류 앙상블

배깅 알고리즘은 모델의 분산을 감소하는 효과적인 방법이지만 모델의 편향을 낮추는 데는 효과적이지 않습니다. 즉, 모델이 너무 단순해서 데이터에 있는 경향을 잘 잡아내지 못합니다. 이것이 배깅을 수행할 때 편향이 낮은 모델, 예를 들어 가지치기하지 않은 결정 트리를 분류기로 사용하여 앙상블을 만드는 이유입니다.

## 약한 학습기를 이용한 에이다부스트

부스팅에서 앙상블은 **weak learner**라고도 하는 매우 ****간단한 분류기로 구성됩니다. 이 분류기는 랜덤 추측보다 조금 성능이 좋을 뿐입니다. 

이하 생략

# Ch8. 감성 분석에 머신 러닝 적용

차후 업데이트

# Ch9. 웹 애플리케이션에 머신 러닝 모델 내장

차후 업데이트 

# Ch10. 회쉬 분석으로 연속적 타깃 변수 예측

트리 기반 모델은 훈련 세트의 범위 밖에 있는 데이터에 대해서는 예측을 하지 못합니다. 이 문제는 연속적인 타깃 값을 예측해야 하는 회귀에서 더 두드러집니다.

랜덤 포레스트의 잔차 그래프도 마찬가지로 랜덤해야한다. 

# Ch11. 레이블되지 않은 데이터 다루기: 군집 분석

## k-평균 알고리즘을 사용하여 유사한 객체 그룹핑

k-means는 **prototype-based clustering**에 속합니다. 프로토타입 기반 군집은 각 클러스터가 하나의 프로토타입으로 표현된다는 뜻입니다. 프로토타입은 연속적인 특성에서는 비슷한 데이터 포인트의 **centroid**(평균)이거나, 범주형 특성에서는 **medoid**(가장 대표되는 포인트나 가장 자주 등장하는 포인트)가 됩니다.

**k-means 알고리즘**

1. 샘플 포인트에서 랜덤하게 k개의 센트로이드를 초기 클러스터 중심으로 선택합니다.
2. 각 샘플을 가장 가까운 센트로이드에 할당합니다.
3. 할당된 샘플들의 중심으로 센트로이드를 이동합니다.
4. 클러스터 할당이 변하지 않거나, 사용자가 지정한 오차나 최대 반복 횟수에 도달할 때까지 단계 2와 3을 반복합니다.

클러스터 내 **SSE** 또는 **클러스터 관성**을 반복적으로 최소화합니다.

$$SSE = \sum^n_{i = 1}\sum^k_{j = 1}w^{(i, j)}||x^{(i)} - \mu^{(j)}||^2_2$$

여기서 $\mu^{(j)}$는 클러스터 j의 대표 포인트(센트로이드)입니다. 샘플 $x^{(j)}$가 클러스터 j안에 있다면 

$w^{(i, j)}=1$이고, 아니면 $w^{(i, j)}=0$입니다. 

n_init=10으로 설정하면 k-means 알고리즘을 각기 다른 랜덤한 센트로이드에서 독립적으로 열 번 실행하여 가장 낮은 SSE를 만드는 하나를 최종 모델로 선택합니다. max_iter 매개변수는 한 번의 실행에서 수행할 최대 반복 횟수를 지정합니다.

k-means의 이론적 단점

1. 알고리즘의 실행 시간이 인풋 크기에 대하여 super-polynomial(시간 복잡도가 다항식에 대하여 bound되지 않음)입니다. 
2. 발견 된 근사는 최적의 클러스터링에 비해 목적 함수와 관련하여 임의로 나쁠 수 있습니다.

### k-mean++로 초기 클러스터 센트로이드를 똑똑하게 할당

초기 센트로이드가 좋지 않게 선택되면 이따금 나쁜 군집 결과를 만들거나 수렴이 느려집니다. 이 문제를 해결하는 한 가지 방법은 같은 데이터셋에서 k-means 알고리즘을 여러 번 실행하여 SSE 입장에서 가장 성능이 좋은 모델을 선택하는 것입니다. 또 다른 방법은 k-means++알고리즘을 통해 초기 센트로이드가 서로 멀리 떨어지도록 위치시키는 것입니다. k-means++의 초기화는 다음과 같이 정리할 수 있습니다.

1. 선택한 k개의 센트로이드를 저장할 빈 집합 **M**을 초기화합니다.
2. 입력 샘플에서 첫 번째 센트로이드 $\bold \mu^{(i)}$를 랜덤하게 선택하고 **M**에 할당합니다.
3. **M**에 있지 않은 각 샘플 $x^{(i)}$에 대해 **M**에 있는 센트로이드까지 최소 제곱 거리 $d(x^{(i)}, M)^2$을 찾습니다.
4. 다음 식과 같은 가중치가 적용된 확률 분포를 사용하여 다음 센트로이드 $\mu^{(p)}$를 랜덤하게 선택합니다.

$$\frac{d(x^{(i)}, \bold M)^2}{\sum_i d(x^{(i)},\bold M)^2}$$

 5. k개의 센트로이드를 선택할 때까지 단계 2와 3을 반복합니다.

 6. 그다음 기본 k-means 알고리즘을 수행합니다.

### 직접 군집 vs 간접 군집

직접 군집(**hard clustering**)은 데이터셋의 샘플이 정확히 하나의 클러스터에 할당되는 알고리즘 종류를 말합니다. 이전 절에서 설명한 k-means 알고리즘이 이에 해당합니다. 간접 군집(**soft clustering**)(이따금 퍼지군집(**fuzzy clustering**)으로 부름)알고리즘은 샘플을 하나 이상의 클러스터에 할당합니다. soft clustering의 대표적인 예는 fuzzy C-Means 알고리즘입니다(soft k-means, fuzzy k-means).

FCM 처리 단계는 k-means와 매우 비슷합니다. 다만 포인트가 직접적으로 클러스터에 할당되는 것을 각 클러스터에 속할 확률로 바꿉니다. 

생략

k-means와 FCM은 매우 비슷한 군집 결과를 만듭니다.

### 엘보우 방법을 사용하여 최적의 클러스터 개수 찾기

### 실루엣 그래프로 군집 품질을 정량화

 **silhouette analysis.** 이 방법은 k-means 이외에 다른 군집 알고리즘에도 적용할 수 있습니다. 실루엣 분석은 클러스터 내 샘플들이 얼마나 조밀하게 모여 있는지를 측정하는 그래프 도구입니다. 데이터셋 샘플 하나에 대한 **silhouette coefficient**를 계산하려면 다음 세 가지 단계를 적용합니다.

1. 샘플 $x^{(i)}$와 동일한 클러스터 내 모든 다른 포인트 사이의 거리를 평균하여 **클러스터 응집력(cluster cohesion) $a^{(i)}$**를 계산합니다.
2. 샘플 $x^{(i)}$와 가장 가까운 클러스터의 모든 샘플 간 평균 거리로 최근접 클러스터의 **클러스터 분리도(cluster separation)** $b^{(i)}$를 계산합니다.
3. 클러스터 응집력과 분리도 사이의 차이를 둘 중 큰 값으로 나누어 실루엣 $s^{(i)}$를 다음과 같이 계산합니다.

$$s^{(i)} = \frac{b^{(i)} - a^{(i)}}{max\{b^{(i)}, a^{(i)}\}}$$

실루엣 계수는 -1과 1 사이 값을 가집니다. 앞 공식을 보면 클러스터 응집력과 분리도가 같으면 실루엣 계수가 0이 됩니다. 또 $b^{(i)} >> a^{(i)}$이면 이상적인 실루엣 계수 1에 가깝게 됩니다. 

## 계층적인 트리로 클러스터 조직화

생략

## DBSCAN을 사용하여 밀집도가 높은 지역 찾기

DBSCAN(Density-Based Spatial Clustering of Applications with Noise). 이 알고리즘은 k-means처럼 원형 클러스터를 가정하지 않습니다. 또 임계치를 수동으로 지정해야 하는 계층적인 방식으로 데이터셋을 나누지 않습니다. 이름이 의미하듯이 밀집도 기반 군집 알고리즘은 샘플이 조밀하게 모인 지역에 클러스터 레이블을 할당합니다. DBSCAN에서 밀집도란 특정 반경 $\epsilon$ 안에 있는 샘플 개수로 정의합니다.

DBSCAN 알고리즘에서는 다음 조건에 따라 샘플에 특별한 레이블이 할당됩니다.

- 어떤 샘플의 특정 반경 $\epsilon$안에 있는 이웃 샘플이 지정된 개수(MinPts) 이상이면 **핵심 샘플(core point)**이 됩니다.
- $\epsilon$ 이내에 MinPts보다 이웃이 적지만 다른 핵심 샘플의 반경 $\epsilon$안에 있으면 **경계 샘플(border point)**이 됩니다.
- 핵심 샘플과 경계 샘플이 아닌 다른 모든 샘플은 **잡음 샘플(noise point)**이 됩니다.

핵심 샘플, 경계 샘플, 잡음 샘플로 레이블을 할당한 후에는 DBSCAN 알고리즘을 다음 두 단계로 요약할 수 있습니다.

1. 개별 핵심 샘플이나 ($\epsilon$ 이내에 있는 핵심 샘플을 연결한) 핵심 샘플의 그룹을 클러스터로 만듭니다.
2. 경계 샘플을 해당 핵심 샘플의 클러스터에 할당합니다.

DBSCAN의 대표적인 장점 중 하나는 k-means처럼 클러스터 모양을 원형으로 가정하지 않는다는 것입니다. 또 DBSCAN은 k-means나 계층 군집과는 달리 모든 샘플을 클러스터에 할당하지 않고 잡음 샘플을 구분하는 능력이 있습니다. DBSCAN은 잡음 샘플에 -1 레이블을 할당합니다.

DBSCAN의 몇몇 단점도 이야기해 보죠. 데이터셋에 훈련 샘플 개수가 고정되어 있다 가정하고, 특성 개수가 늘어나면 차원의 저주로 인한 역효과가 증가합니다. 특히 유클리디안 거리 측정을 사용할 때 문제가 됩니다. 차원의 저주가 DBSCAN만의 문제는 아닙니다. 유클리디안 거리 측정을 사용하는 다른 군집 알고리즘에도 영향을 미칩니다. 예를 들어 k-means와 계층 군집 알고리즘도 해당됩니다. DBSCAN이 좋은 군집 결과를 만들려면 두 개의 하이퍼파라미터(MinPts와 $\epsilon$)를 최적화해야 합니다. 데이터셋에 있는 밀집 영역의 크기가 많이 차이 나면 알맞은 MinPts와 $\epsilon$ 조합을 찾는 일이 어렵습니다. 

[2.3. Clustering - scikit-learn 0.23.2 documentation](https://scikit-learn.org/stable/modules/clustering.html)