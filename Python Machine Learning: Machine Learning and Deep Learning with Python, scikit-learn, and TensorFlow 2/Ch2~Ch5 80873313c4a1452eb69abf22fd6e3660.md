# Ch2~Ch5

# Ch2. 간단한 분류 알고리즘 훈련

## 인공 뉴런: 초기 머신 러닝의 간단한 역사

 

$$\Delta w_j = \eta(y^{(i)} - \hat y^{(i)})x^{(i)}_j $$

$\eta$는 learning rate입니다. 퍼셉트론이 클래스 레이블을 정확히 예측한 두 경우는 가중치가 변경되지 않고 그대로 유지됩니다. 잘못 예측했을 때는 가중치를 양성 또는 음성 클래스 방향으로 이동시킵니다. 가중치 업데이트는 $x_j^{(i)}$값에 비례합니다. 퍼셉트론은 두 클래스가 선형적으로 구분되고 학습률이 충분히 작을 때만 수렴이 보장됩니다. 두 클래스를 선형 결정 경계로 나눌 수 없다면 훈련 데이터셋을 반복할 최대 횟수(에포크(epoch))를 지정하고 분류 허용 오차를 지정할 수 있습니다. 그렇지 않으면 퍼셉트론은 가중치 업데이트를 멈추지 않습니다. 

관례에 따라 객체의 초기화 과정에서 생성하지 않고 다른 메서드를 호출하여 만든 속성은 밑줄(_)을 추가합니다.  예를 들어 self.w_와 같습니다.

```python
import numpy as np

class Perceptron(object):
    """퍼셉트론 분류기
    
    매개변수
    ------------
    eta : float
     학습률 (0과 1사이)
    n_iter : int
    가중치 무작위 초기화를 위한 난수 생성기 시드
    
    속성
    -------------
    w_ : 1d-array
     학습된 가중치
    errors_ : list
     에포크마다 누적된 분류 오류 
     
    """
    
    def __init__(self, eta = 0.01, n_iter = 50, random_state = 1):
        self.eta = eta
        self.n_iter = n_iter
        self.random_state = random_state
        
    def fit(self, x, y):
        """훈련 데이터 학습
        
        매개변수
        -----------
        X : {array-like}, shape = [n_samples, n_features]
         n_samples개의 샘플과 n_features개의 특성으로 이루어진 훈련 데이터 
        Y : array-like, shape = [n_samples]
         타깃 값
         
        반환값
        ----------
        self : object
        
        """
        rgen =  np.random.RandomState(self.random_state)
        self.w_ = rgen.normal(loc = 0, scale = 0.01, size = 1 + X.shape[1])
        
        self.errors_ = []
        
        for _ in range(self.n_iter):
            errors = 0
            for xi, target in zip(X, y):
                update = self.eta * (target - self.predict(xi))
                self.w_[1:] += update * xi
                self.w_[0] += update
                errors += int(update != 0)
            self.errors_.append(errors)
        return self
    
    def net_input(self, X):
        """최종 입력 계산"""
        return np.dot(X, self.w_[1:]) + self.w_[0]
    
    def predict(self, X):
        """단위 계단 함수를 사용하여 클래스 레이블을 반환합니다"""
        return np.where(self.net_input(X) >= 0, 1, -1)
```

가중치를 0으로 초기화하지 않는 이유는 가중치가 0이 아니어야 학습률이 분류 결과에 영향을 주기 때문입니다. 가중치가 0으로 초기화되어 있다면 학습률 파라미터 eta는 가중치 벡터의 방향이 아니라 크기에만 영향을 미칩니다.  $w^{(0)}$가 0이 아니라면 $\eta$값의 크기에 따라 $w^{(1)}$방향이 바뀔 수 있습니다. 

fit메서드는 가중치를 초기화한 후 훈련 세트에 있는 모든 개개의 샘플을 반복 순회하면서 이전절에서 설명한 퍼셉트론 학습 규칙에 따라 가중치를 업데이트합니다. 클래스 레이블은 predict메서드에서 예측합니다. fit메서드에서 가중치를 업데이트하기 위해 predict메서드를 호출하여 클래스 레이블에 대한 예측을 얻습니다. predict메서드는 모델이 학습되고 난 후 새로운 데이터의 클래스 레이블을 예측하는 데도 사용할 수 있습니다. 에포크마다 self.errors_ 리스트에 잘못 분류된 횟수를 기록합니다. 나중에 훈련하는 동안 얼마나 퍼셉트론을 잘 수행했는지 분석할 수 있습니다. 

## ADAptive Linear NEuron(ADALINE)과 학습의 수렴

아달린은 연속 함수로 비용 함수를 정의하고 최소화합니다. 이전 퍼셉트론과 가장 큰 차이점은 가중치를 업데이트하는 데 퍼셉트론처럼 단위 계단 함수 대신 선형 활성화 함수를 사용하는 것입니다. 

![Ch2~Ch5%2080873313c4a1452eb69abf22fd6e3660/Untitled.png](Ch2~Ch5%2080873313c4a1452eb69abf22fd6e3660/Untitled.png)

아달린 알고리즘은 진짜 클래스 레이블과 선형 활성화 함수의 실수 출력 값을 비교하여 모델의 오차를 계산하고 가중치를 업데이트합니다. 반대로 퍼셉트론은 진짜 클래스 레이블과 예측 클래스 레이블을 비교합니다. 

### 경사 하강법으로 비용 함수 최소화

아달린은 계산된 출려과 진짜 클래스 레이블 사이의 Sum of Squared Errors(SSE)으로 가중치를 학습할 비용 함수를 정의합니다. 

$$J(\mathbf w) = \frac{1}{2}\sum(y^{(i)} - \phi(z^{(i)})^2$$

$$\frac{\partial J }{\partial w_j} = -\sum_i(y^{(i)} - \phi(z^{(i)})x_j^{(i)}$$

따라서 가중치 $w_j$의 업데이트 공식을 다음과 같이 쓸 수 있습니다.

$$\Delta w_j = -\eta\frac{\partial J }{\partial w_j} = \eta \sum_i(y^{(i)} - \phi(z^{(i)}))x_j^{(i)}$$

퍼셉트론과 아달린이 동일해 보이지만 $\phi(z^{(i)})$가 정수 클래스 레이블이 아니고 실수입니다. 또 훈련 세트에 있느 모든 샘플을 기반으로 가중치 업데이트를 계산합니다(각 샘플마다 가중치를 업데이트하지는 않습니다). 이 방식을 batch gradient descent이라고도 합니다. 

### 파이썬으로 아달린 구현

```python
class AdalineGD(object):
    """적응형 선형 뉴런 분류기 
    
    매개변수
    ----------
    eta : float
     학습률(0과 1사이)
    n_iter : int
     훈련 데이터셋 반복 횟수
    random_state : int
     가중치 무작위 초기화를 위한 난수 생성기 시드
     
    속성
    -----------
    w_ : 1d-array
     학습된 가중치
    cost_ : list
     에포크마다 누적된 비용 함수의 제곱합
     
    """
    def __init__(self, eta = 0.01, n_iter = 50, random_state = 1):
        self.eta = eta
        self.n_iter = n_iter
        self.random_state = random_state
        
    def fit(self, X, y):
        """훈련 데이터 학습
        
        매개변수
        -----------
        매개변수
        -----------
        X : {array-like}, shape = [n_samples, n_features]
         n_samples개의 샘플과 n_features개의 특성으로 이루어진 훈련 데이터 
        Y : array-like, shape = [n_samples]
         타깃 값
         
        반환값
        ----------
        self : object
        
        """
        rgen = np.random.RandomState(self.random_state)
        self.w_ = rgen.normal(loc = 0, scale = 0.01, size = 1 + X.shape[1])
        self.cost_ = []
        
        for i in range(self.n_iter):
            net_input = self.net_input(X)
            output = self.activation(net_input)
            errors = (y - output)
            self.w_[1:] += self.eta * X.T.dot(errors)
            self.w_[0] += self.eta * errors.sum() # x_j = 1이므로 
            cost = (errors ** 2).sum() / 2
            self.cost_.append(cost)
        return self
    
    def net_input(self, X):
        """최종 입력 계산"""
        return np.dot(X, self.w_[1:]) + self.w_[0]
    
    def activation(self, X):
        """선형 활성화 계산"""
        return X
    
    def predict(self, X):
        """단위 계산 함수를 사용하여 클래스 레이블을 변경합니다"""
        return np.where(self.activation(self.net_input(X)) >= 0, 1, -1)
```

전체 훈련 데이터셋을 기반으로 grad를 계산합니다. 이 코드의 activation 메서드는 단순한 항등 함수이기 때문에 아무런 영향을 미치지 않습니다. 

너무 큰 학습률을 설정하면 비용 함수를 최소화하지 못하고 오차는 에포크마다 점점 더 커집니다. 전역 최솟값을 지나칠 수 있기 때문입니다. 

### 특성 스케일을 조정하여 경사 하강법 결과 향상

표준화를 하여 경사 하강법 학습이 좀 더 빠르게 수렴되도록 도울 수 있습니다. 

### 대규모 머신 러닝과 확률적 경사 하강법

매우 큰 데이터셋에서 배치 경사 하강법을 실행하면 계산 비용이 매우 많이 듭니다. 전역 최솟값으로 나아가는 단계마다 매번 전체 훈련 데이터셋을 다시 평가해야 하기 때문입니다. 

stochastic gradient descent는 배치 경사 하강법의 다른 대안으로 인기가 높습니다. 이따금 반복 또는 온라인 경사 하강법이라고도 부릅니다. 다음 첫 번째 수식처럼 모든 샘플 $x^{(i)}$에 대하여 누적된 오차의 합을 기반으로 가중치를 업데이트하는 대신 두 번째 수식처럼 각 훈련 샘플에 대해서 조금씩 가중치를 업데이트합니다.

$$\Delta \mathbf w = \eta \sum_i(y^{(i)} - \phi(z^{(i)}))x^{(i)} \\ \Delta \mathbf w = \eta (y^{(i)} - \phi(z^{(i)}))x^{(i)}$$

SGD를 경사 하강법의 근사로 생각할 수 있지만 가중치가 더 자주 업데이트되기 때문에 수렴 속도가 훨씬 빠릅니다. grad가 하나의 훈련 샘플을 기반으로 계산되므로 오차의 궤적은 batch grad desc보다 훨씬 어지럽습니다. 비선형 비용 함수를 다룰 때 얕은 지역 최솟값을 더 쉽게 탈출할 수 있어 장점이 되기도 합니다.  SGD에서 만족스러운 결과를 얻으려면 훈련 샘플 순서를 무작위하게 주입하는 것이 중요합니다. 또 순환되지 않도록 에포크마다 훈련 세트를 섞는 것이 좋습니다.

---

**NOTE** 

확률적 경사 하강법 구현에서 종종 고정된 학습률 $\eta$를 시간이 지남에 따라 적응적인 학습률로 대체합니다.

$$\frac{c_i}{[\text{number of iterations}] + c_2}$$

여기서 $c_1$과 $c_2$는 상수입니다. SGD는 전역 최솟값에 도달하지 못하지만 매우 가까운 지역에 근접합니다. 적응적 학습률을 사용하면 최솟값에 더욱 가깝게 다가갈 수 있습니다.

---

SGD의 또 다른 장점은 online learning으로 사용할 수 있다는 것입니다. 온라인 학습에서 모델은 새로운 훈련 데이터가 도착하는 대로 훈련됩니다. 많은 양의 훈련 데이터가 있을 때도 유용합니다. 예를 들어 고객 데이터를 처리하는 웹 API입니다. 온라인 학습을 사용해서 시스템은 변화에 즉시 적응합니다. 저장 공간에 제약이 있다면 모델을 업데이트한 후 훈련 데이터를 버릴 수 있습니다. 

---

**NOTE**

batch grad desc보다 SGD사이의 절충점이 **mini-batch learning**입니다. 미니 배치 학습은 훈련 데이터의 작은 일부분으로 batch grad desc을 적용한다고 이해할 수 있ㅅ브니다. 배치 grad desc에 비해 장점은 가중치 업데이트가더 자주 일어나므로 수렴속도가 더 빠릅니다. 또 미니 배치 학습은 SGD에서 훈련 샘플을 순회하는 for 반복을 벡터화된 연산으로 바꾸어 주므로 학습 알고리즘의 계산 효율성이 크게 향상됩니다.

---

```python
class AdalineSGD(object):
    """ADAptive LInear NEuron 분류기
    
    매개변수
    -----------
    eta : float
     학습률 (0과 1 사이)
    n_iter : int
     훈련 데이터셋 반복 횟수
    shuffle : bool (default : True)
     True로 설정하면 같은 반복이 되지 않도록 에포크마다 훈련 데이터를 섞습니다
    random_state : int
     가중치 무작위 초기화를 위한 난수 생성기 시드
     
    속성
    -----------
    w_ : 1d-array
     학습된 가중치
    cost_ : list
     모든 훈련 샘플에 대해 에포크마다 누적된 평균 비용 함수의 제곱합
     
    """
    def __init__(self, eta = 0.01, n_iter = 10, shuffle = True, random_state = None):
        self.eta = eta
        self.n_iter = n_iter
        self.w_initialized = False
        self.shuffle = shuffle
        self.random_state = random_state
        
    def fit(self, X, y):
        """훈련 데이터 학습
        
        매개변수
        -----------
        매개변수
        -----------
        X : {array-like}, shape = [n_samples, n_features]
         n_samples개의 샘플과 n_features개의 특성으로 이루어진 훈련 데이터 
        Y : array-like, shape = [n_samples]
         타깃 값
         
        반환값
        ----------
        self : object 
        
        """
        self._initialize_weights(X.shape[1])
        self.cost_ = []
        for i in range(self.n_iter):
            if self.shuffle:
                X, y = self._shuffle(X, y)
            cost = []
            for xi, target in zip(X, y):
                cost.append(self._update_weights(xi, target))
            avg_cost = sum(cost) / len(y)
            self.cost_.append(avg_cost)
        return self
    
    def partial_fit(self, X, y):
        """가중치를 다시 초기화하지 않고 훈련 데이터를 학습합니다"""
        if not self.w_initailized:
            self._initialized_weights(X.shape[1])
        if y.ravel().shape[0] > 1:
            for xi, target in zip(X, y):
                self._update_weights(xi, target)
        else:
            self._update_weights(xi, target)
        return self
    
    def _shuffle(self, X, y):
        """훈련 데이터를 섞습니다"""
        r = self.rgen.permutation(len(y))
        return X[r], y[r]
    
    def _initialized_weights(self, m):
        """랜덤한 작은 수로 가중치를 초기화합니다"""
        self.rgen = np.random.RandomState(self.random_state)
        self.w_ = self.rgen.normal(loc = 0, scale = 0.01, size = 1 + m)
        self.w_initailized = True
        
    def _update_weights(self, xi, target):
        """아달린 학습 규칙을 적용하여 가중치를 업데이트합니다"""
        output = self.activation(self.net_input(xi))
        error = (target - output)
        self.w_[1:] += self.eta * xi.dot(error)
        self.w_[0] += self.eta * error
        cost = 0.5 * error**2
        return cost
    
    def net_input(X, y):
        """최종 입력 계산"""
        return np.dot(X, self.w_[1:]) + self.w_[0]
    
    def activation(self, X):
        """선형 활성화 계산"""
        return X
    
    def predict(self, X):
        """단위 계단 함수를 사용하여 클래스 레이블을 반환합니다"""
        return np.where(self.activation(self.net_input(X)) >= 0, 1, -1)
```

# Ch3. 사이킷런을 타고 떠나는 머신 러닝 분류 모델 투어

머신러닝 알고리즘을 훈련하기 위한 5가지 주요 단계

1. 특성을 선택하고 훈련 샘플을 모은다.
2. 성능 지표를 선택한다.
3. 분류 모델과 최적화 알고리즘을 선택한다.
4. 모델의 성능을 평가한다.
5. 알고리즘을 튜닝한다.

## 사이킷런 첫걸음: 퍼셉트론 훈련

사이킷런의 많은 함수와 클래스 메서드는 문자열 형태의 클래스 레이블을 다룰 수 있습니다. 정수 레이블이 권장되는 이유는 사소한 실수를 피할 수 있고 작은 메모리 영역을 차지하므로 계산 성능을 향상시키기 때문입니다. 클래스 레이블을 정수로 인코딩하는 것은 대부분 머신 러닝 라이브러리들의 공통된 관례이기도 합니다.

## 로지스틱 회귀를 사용한 클래스 확률 모델링

$$logit(P(y = 1|x)) = \mathbf w^T \mathbf x$$

어던 샘플이 특정 클래스에 속할 확률을 예측하는 것이 관심 대상이므로 logit함수를 거꾸로 뒤집습니다. 이 함수를 로지스틱 시그모이드 함수라고 합니다. 함수 모양이 S자 형태를 띠기 때문에 간단하게 줄여서 **시그모이드 함수**라고도 합니다. 

$$\phi(z) = \frac{1}{1 + e^{-z}}$$

### 로지스틱 비용 함수의 가중치 학습

likelihood L를 정의하겠습니다. 각 샘플이 서로 독립정적이라고 가정합니다. 여기서 $z = \mathbf w^T \mathbf x$

$$L(\mathbf w) = p(y | x ; w) = \prod^n_{i = 1}P(y^{(i)} | x^{(i)};w) = \prod^n_{i = 1}(\phi(z^{(i)}))^{y^{(i)}}(1 - \phi(z^{(i)}))^{1 - y^{(i)}}$$

실전에서는 이 공식의 로그를 최대화하는 것이 더 쉽습니다. 이 함수를 로그 가능도 함수라고 합니다.

$$l(\mathbf w) = logL(\mathbf w) = \sum^n_{i = 1}\left [y^{(i)}log(\phi(z^{(i)})) + (1 - y^{(i)})log(1 - \phi(z^{(i)}))\right ] $$

첫째, 로그 함수를 적용하면 가능도가 매우 작을 때 일어나는 수치상의 underflow를 미연에 방지합니다. 둘째, 계수의 곱을 계수의 합으로 바꿀 수 있습니다. 이렇게 하면 도함수를 구하기 쉽습니다. 

### 아달린 구현을 로지스틱 회귀 알고리즘으로 변경

$$J(\mathbf w) = -\sum^n_{i = 1}\left [y^{(i)}log(\phi(z^{(i)})) + (1 - y^{(i)})log(1 - \phi(z^{(i)}))\right ] $$

J를 w에 관하여 미분해보면 RMSE를 목적함수를 가질 때와 동일한 결과가 나온다. 그래서 활성화 함수가 로지스틱인 것을 제외하면 퍼셉트론과 다를 것이 없다. 

```python
def fit(self, X, y):
        """훈련 데이터 학습
        
        매개변수
        -----------
        매개변수
        -----------
        X : {array-like}, shape = [n_samples, n_features]
         n_samples개의 샘플과 n_features개의 특성으로 이루어진 훈련 데이터 
        Y : array-like, shape = [n_samples]
         타깃 값
         
        반환값
        ----------
        self : object 
        
        """
        rgen = np.random.RandomState(self.random_state)
        self.w_ = rgen.normal(loc = 0, scale = 0.01, size = 1 + X.shape[1])
        self.cost_ = []
        
        for i in range(self.n_iter):
            net_input = self.net_input(X)
            output = self.activation(net_input)
            errors = (y - output)
            self.w_[1:] += self.eta * X.T.dot(errors)
            self.w_[0] += self.seta * errors.sum()
        
            # 오차 제곱합 대신 로지스틱 비용을 계산합니다
            cost = (-y.dot(np.log(output)) - ((1 - y).dot(np.log(1 - output))))
        return self
    

    
    def net_input(X, y):
        """최종 입력 계산"""
        return np.dot(X, self.w_[1:]) + self.w_[0]
    
    def activation(self, X):
        """로지스틱 시그모이드 활성화 계산"""
        return 1 / (1 + np.exp(-np.clip(z, -250, 250))) # np.clip(array, array_min, array_max) 최솟값 보다 작으면 최솟값으로 최댓값 보다 크면 최댓값으로 변환시킴 
    
    def predict(self, X):
        """단위 계단 함수를 사용하여 클래스 레이블을 반환합니다"""
        return np.where(self.net_input(X) >= 0, 1, 0)
        # 다음과 동일 
        # return np.where(self.activation(self.net_input(X)) >= 0, 0.5, 0)
```

### 사이킷런을 사용하여 로지스틱 회귀 모델 훈련

```python
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(solver = 'liblinear', multi_class = 'auto', C = 100, random_state = 1)
```

샘플 하나의 클래스 레이블을 예측할 때 주의할 점이 있습니다. 사이킷런은 입력 데이터로 2차원 배열을 기대합니다. 하나의 행을 2차원 포맷으로 먼저 변경해야 합니다. 

```python
lr.predict(X_test_std[0, :].reshape(1, -1))
# 다른 방법
# np.expand_dims(X_test_std[0, :], axis = 0
# X_test_std[0:1, :]
```

### 규제를 사용하여 과대적합 피하기

$$J(\mathbf w) = -\sum^n_{i = 1}\left [y^{(i)}log(\phi(z^{(i)})) + (1 - y^{(i)})log(1 - \phi(z^{(i)}))\right ]  + \frac{\lambda}{2}||\mathbf w||^2$$

매개변수 C는 규제 하이퍼파라미터 $\lambda$의 역수입니다. 결과적으로 역 규제 파라미터 C의 값을 감소시키면 규제 강도가 증가합니다. 

## 서포트 벡터 머신을 사용한 최대 마진 분류

필요한 부분만 정리하였습니다. 

- SVM은 local minima에 빠지는 걱정을 전혀 하지 않아도 됩니다.
- 로지스틱 회귀와 SVM은 종종 매우 비슷한 결과를 만듭니다. 로지스틱 회귀는 훈련 데이터의 조건부 가능도를 최대화하기 때문에 SVM보다 이상치에 민감하다. SVM은 결정 경계에 가장 가까운 포인트(서포트 벡터)에 대부분 관심을 둡니다. 반면 로지스틱 회귀는 모델이 간단하고 구현하기가 더 쉬운 장점이 있습니다. 또 로지스틱 회귀 모델은 업데이트가 용이하므로 스트리밍 데이터를 다룰 때 적합합니다.
- 사이킷런의 SGDClassifier 클래스는 partial_fit메서드를 사용하여 온라인 학습을 지원합니다.
- kernel method의 기본 아이디어는 매핑 함수를 사용하여 원본 특성의 비선형 조합을 선형적으로 구분되는 고차원 공간에 투영하는 것입니다.

## 커널 SVM을 사용하여 비선형 문제 풀기

SVM으로 비선형 문제를 풀기 위해 매핑 함수 $\phi$를 사용하여 훈련 데이터를 고차원 특성 공간으로 변환합니다. 그다음 이 새로운 특성 공간에서 데이터를 분류하는 선형 SVM 모델을 훈련합니다. 동일한 매핑 함수 $\phi$를 사용하여 새로운 본 적 없는 데이터를 변환하고 선형 SVM 모델을 사용하여 분류할 수 있습니다. 이런 매핑 방식의 한 가지 문제점은 새로운 특성을 만드는 계산 비용이 매우 비싸다는 것입니다. 특히 고차원 데이터일 때 더욱 그렇습니다. 여기에 소위 커널 기법이 등장하게 됩니다. SVM을 훈련하기 위해 quadartic 프로그래밍 문제를 어떻게 푸는지 상세히 다루지는 않겠습니다. 실전에서 필요한 것은 점곱 $x^{(i)T}x^{(j)}$를 $\phi(x^{(i)})^T\phi(x^{(j)})$로 바꾸는 것입니다. 두 포인트 사이 점곱을 계산하는 데 드는 높은 비용을 절감하기 위해 **커널 함수** $\mathcal{K}(x^{(i)}, x^{(j)}) = \phi(x^{(i)})^T\phi(x^{(j)})$를 정의합니다.

가장 널리 사용되는 커널 중 하나는 Radial Basis Function(RBF)입니다. 

## 결정 트리 학습

정보 이득이 최대가 되는 특성으로 데이터를 나눈다. 보통 불순도 조건을 바꾸어 트리를 평가하는 것보다 가지치기 수준을 바꾸면서 튜닝하는 것이 훨씬 낫다. 

랜덤포레스트에서 신경 서야 할 파라미터는 랜덤 포레스트가 만들 트리 개수 하나이다. 

## KNN

KNN은 전형적인 lazy learner이다. 훈련 데이터에서 판별 함수를 학습하는 대신 훈련 데이터셋을 메모리에 저장하기 때문이다. 

---

**NOTE**

모수 모델은 새로운 데이터 포인트를 분류할 수 있는 함수를 학습하기 위해 훈련 데이터셋에서 모델 파라미터를 추정합니다. 훈련이 끝나면 원본 훈련 데이터셋이 더 이상 필요하지 않습니다. 전형적인 모수 모델은 퍼셉트론, 로지스틱 회귀, 선형 SVM입니다. 반대로 비모수 모델은 고정된 개수의 파라미터로 설명될 수 없습니다. 훈련 데이터가 늘어남에 따라 파라미터 개수도 늘어납니다. 지금까지 본 모델 중 비모수 모델 두 개는 결정 트리/랜덤 포레스트와 커널 SVM입니다. 결정 트리는 분할을 위한 노드가 늘어나고 커널 SVM은 dual form을 풀기 위한 커널 함수 계산이 늘어납니다. 

KNN은 비모수 모델에 속하며 인스턴스 기반 모델이라고 합니다. 인스턴스 기반 모델은 훈련 데이터셋을 메모리에 저장하는 것이 특징입니다. 게으른 학습은 인스턴스 기반 학습의 특별한 경우이며 학습 과정에서 비용이 전혀 들지 않습니다.

---

메모리 기반 방식의 분류기는 수집된 새로운 훈련 데이터에 즉시 적응할 수 있는 것이 주요 장점입니다. 새로운 샘플을 분류하는 계산 복잡도는 단점입니다. 데이터셋의 차원(특성)이 적고 알고리즘이 KD-트리 같은 효율적인 데이터 구조로 구현되어 있지 않다면 최악의 경우 훈련 데이터셋의 샘플 개수에 선형적으로 증가합니다. 또 훈련 단계가 없기 때문에 훈련 샘플을 버릴 수 없습니다. 대규모 데이터셋에서 작업한다면 저장 공간에 문제가 생깁니다.

KNN은 차원의 저주 때문에 overfitting 되기 쉽습니다. 

# Ch4. 8좋은 훈련 세트 만들기: 데이터 전처리

## 누락된 데이터 다루기

```python
import numpy as np
from sklearn.impute import SimpleImputer

simr = SimpleImputer(missing_values = np.nan, strategy = 'mean')
simr = simr.fit(df.values)
imputed_data = simr.transform(df.values)
imputed_data
```

```python
import numpy as np
from sklearn.impute import MissingIndicator
X1 = np.array([[np.nan, 1, 3],
                [4, 0, np.nan],
                [8, 1, 0]])
X2 = np.array([[5, 1, np.nan],
                [np.nan, 2, 3],
                [2, 4, 0]])
indicator = MissingIndicator()
indicator.fit(X1)
MissingIndicator()
X2_tr = indicator.transform(X2)
X2_tr
```

### 사이킷런 추정기 API 익히기

Imputer 클래스는 데이터 변환에 사용되는 사이킷런의 **transformer** 클래스입니다. 이런 추정기의 주요 메서드 두 개는 fit과 transform입니다. fit 메서드를 사용하여 훈련 데이터에서 모델 파라미터를 학습합니다. transform 메서드를 사용하여 학습한 파라미터로 데이터를 변환합니다. 변환하려는 데이터 배열은 모델 학습에 사용한 데이터의 특성 개수와 같아야 합니다. 

![Ch2~Ch5%2080873313c4a1452eb69abf22fd6e3660/Untitled%201.png](Ch2~Ch5%2080873313c4a1452eb69abf22fd6e3660/Untitled%201.png)

3장에서 사용한 분류기는 transformer 클래스와 개념상 매우 유사한 API를 가진 사이킷런의 **estimator**입니다. estimator는 predict메서드가 있지만 transform 메서드도 가질 수 있습니다. 

![Ch2~Ch5%2080873313c4a1452eb69abf22fd6e3660/Untitled%202.png](Ch2~Ch5%2080873313c4a1452eb69abf22fd6e3660/Untitled%202.png)

## 범주형 데이터 다루기

### 순서가 있는 특성과 순서가 없는 특성

사이킷런은 ordinal regression에 대한 기능을 제공하지 않습니다.

### 순서 특성 매핑

학습 알고리즘이 순서 특성을 올바르게 인식하려면 범주형의 문자열 값을 정수로 바꾸어야 합니다. 

```python
size_mapping = {
    'XL': 3,
    'L': 2,
    'M': 1
}
df['size'] = df['size'].map(size_mapping)
```

만약 나중에 정수 값을 다시 원래 문자열로 바꾸고 싶다면 간단히 거꾸로 매핑하는 딕셔너리를 정의하면 됩니다.

```python
inv_size_mapping = {v: k for k, v in size_mapping.items()}
df['size'].map(inv_size_mapping)
```

### 클래스 레이블 인코딩

많은 머신러닝 라이브러리는 클래스 레이블이 정수로 인코딩되었을 것이라고 기대합니다. 

```python
import numpy as np

class_mapping = {label:idx for idx, label in enumerate(np.unique(df['classlabel']))}
df['classlabel'] = df['classlabel'].map(class_mapping)
```

```python
inv_class_mapping = {v: k for k, v in class_mapping.items()}
df['classlabel'] = df['classlabel'].map(inv_class_mapping)
```

다른 방법으로 사이킷런에 구현된 LabelEncoder 클래스를 사용하면 편리합니다. fit_transform 메서드는 fit 메서드와 transform 메서드를 합쳐 놓은 단축 메서드입니다. 

```python
from sklearn.prerocessing import LabelEncoder

class_le = LabelEncoder()
y = class_le.fit_transform(df['classlabel'].values)
```

LabelEncoder는 target 레이블을 인코딩하기 위한 클래스이므로 입력 데이터로 1차원 배열을 기대합니다. 앞 코드에서 color 열만 추출해서 LabelEncoder 객체에 주입한 이유입니다. 데이터셋에 변경해야 할 열이 많다면 동일한 작업을 반복해야 하므로 번거롭습니다. 범주형 데이터를 정수로 인코딩하는 OrdinalEncoder와 판다스 df의 열마다 다른 변환을 적용하도록 도와주는 ColumnTransformer가 추가되었습니다. 이 두 클래스를 이용하면 여러 개의 열을 한 번에 정수로 변환할 수 있습니다.

```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OrdinalEncoder

ord_enc = OrdinalEncoder(dtype = np.int)
col_trans = ColumnTransformer([('ord_enc', ord_enc, ['color'])])
X_trans = col_trans.fit_transform(df)
```

ColumnTransformer는 첫 번째 매개변수로 transformer의 리스트를 받습니다. 트랜스포머는 이름, 변환기, 변환할 열의 리스트로 이루어진 튜플입니다. 

ColumnTransformer에 사용한 변환기는 named_transformers_ 속성에서 앞서 지정한 ord_enc 이름으로 참조할 수 있습니다. 정수로 인코딩된 값을 다시 문자열로 변환하려면 다음과 같이 OrdinalEncoder의 inverse_transform 메서드를 호출합니다. 

```python
col_trans.named_transformers_['ord_enc'].inverse_transform(X_trans)
```

기본적으로 OneHotEncoder의 transform메서드는 **sparse matrix**을 반환합니다. 배열 내용을 보려면 희소 행렬의 toarray 메서드로 일반(밀집) 넘파이 배열로 변환합니다. 희소 행렬은 대량의 데이터셋을 저장할 때 효율적입니다. 특히 배열에 0이 많이 포함되어 있을 때 유용합니다. 사이킷런의 많은 함수는 희소 행렬을 지원합니다. `OneHotEncoder(..., sparse = False)` 처럼 인코더를 초기화하면 toarray 단계를 생략하고 바로 일반 넘파이 배열을 얻을 수 있습니다. 

```python
from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(categories = 'auto')
col_trans = ColumnTransformer([('oh_enc', oh_enc, [0])], remainder = 'passthrough')
col_trans.fit_transform(X)
```

`remainder = 'passthrough'`는 변환한 열과 기존의 열들을 합쳐서 반환합니다. 

ohe된 데이터셋을 사용할 때 다중 공선성 문제를 유념하세요. 어떤 알고리즘에는 이슈가 될 수 있습니다(예를 들어 역행렬을 구해야 하는 경우). 특성 간의 상관관계가 높으면 역행렬을 계산하기 어려워 수치적으로 불안정해집니다. 변수 간의 상관관계를 감소하려면 ohe된 배열에서 특성 열 하나를 삭제합니다. 이렇게 특성을 삭제해도 잃는 정보는 없습니다. 

`ohe.fit_transform(X).toarray()[:, 1:]`

## 특성 스케일 맞추기

표준화는 이상치 정보가 유지되기 때문에 제한된 범위로 데이터를 조정하는 min-max 스케일 변환에 비해 알고리즘이 이상치에 덜 민감합니다. 

```python
from sklearn.preprocessing import StandardScaler

stdsc = StandardScaler()
X_train_std = stdsc.fit_transform(X_train)
X_test_std = stdsc.transform(X_test)
```

## 유용한 특성 선택

### 모델 복잡도 제한을 위한 L1 규제와 L2 규제

### 순차 특징 선택 알고리즘

모델 복잡도를 줄이고 과대적합을 피하는 다른 방법은 특징 선택을 통한 차원 축소입니다. 규제가 없는 모델에서 특히 유용합니다. 차원 축소 기법에는 두 개의 주요 카테고리인 특징 선택과 특성 추출이 있습니다. 특징 선택은 원본 특성에서 일부를 선택합니다. 특성 추출은 일련의 특성에서 얻은 정보로 새로운 특성을 만듭니다. 

순차 특성 선택(sequential feature selection)알고리즘은 greedy search algorithm으로 초기 d차원의 특성 공간을 k < d인 k 차원의 특성 부분 공간으로 축소합니다. 특성 선택 알고리즘은 주어진 문제에 가장 관련이 높은 특성 부분 집합을 자동으로 선택하는 것이 목적입니다. 관계없는 특성이나 잡음을 제거하여 계산 효율성을 높이고 모델의 일반화 오차를 줄입니다. 

# Ch5. 차원 축소를 사용한 데이터 압축

## 주성분 분석을 통한 비지도 차원 축소

생략

## 선형 판별 분석을 통한 지도 방식의 데이터 압축

$$J = \frac{\mathbf w^T S_B \mathbf w}{\mathbf w^T S_W \mathbf w}$$

분모를 일정하게 유지하면서 분자를 최대화하는 최적화 문제로 보고 라그랑주 승수법을 적용하면 다음과 같은 결과를 얻습니다.

$$S_W^{-1}S_B\mathbf w = \lambda \mathbf w$$

결국 $S_W^{-1}S_B$의 고윳값 분해 문제가 됩니다. 

LDA는 데이터가 정규분포라고 가정합니다. 또 클래스가 동일한 공분산 행렬을 가지고 샘플은 서로 통계적으로 독립적이라고 가정합니다. 하나 이상의 가정이 위반되더라도 여전히 LDA는 차원 축소를 상당히 잘 수행합니다. 

이하 생략

## 커널 PCA를 사용하여 비선형 매핑

### 커널 함수와 커널 트릭

커널 PCA를 통한 비선형 매핑을 수행하여 데이터를 고차원 공간으로 변환합니다. 그다음 고차원 공간에 표준 PCA를 사용하여 샘플이 선형 분류기로 구분될 수 있는 저차원공간으로 데이터를 투영합니다. 이 방식의 단점은 계산 비용이 매우 비싸다는 것입니다. 여기에 **kernel trick**이 등장합니다. 커널 트릭을 사용하면 원본 특성 공간에서 두 고차원 특성 벡터의 유사도를 계산할 수 있습니다.

공분산 행렬에서 비선형 매핑을 통한 비선형 특성 조합으로 원본 특성 공간의 샘플 사이의 점곱을 대체했습니다. 

$$\begin{aligned} Cov &= \frac{1}{n}\sum^n_{i = 1}\phi(x^{(i)})\phi(x^{(j)})^T \\ &= \frac{1}{n}\phi(\mathbf X)^T \phi(\mathbf X) \end{aligned}$$

커널 트릭을 사용하여 샘플 x끼리의 $\phi$함수 점곱을 커널 함수 $\mathcal K$로 바꿈으로써 고유 벡터를 명시적으로 계산할 필요가 없습니다.

$$\mathcal K(x^{(i)}, x^{(j)}) = \phi(x^{(i)})^T\phi(x^{(j)})$$

다른 말로 하면 커널 PCA로 얻은 것은 표준 PCA 방식에서처럼 투영 행렬을 구성한 것이 아니고 각각의 성분에 이미 투영된 샘플입니다. 기본적으로 커널 함수는 두 벡터 사이의 점곱을 계산할 수 있는 함수입니다. 즉, 유사도를 측정할 수 있는 함수입니다. 

1. 커널 행렬 $K$를 다음 식으로 계산합니다. 샘플의 모든 쌍에 대해 구합니다.

![Ch2~Ch5%2080873313c4a1452eb69abf22fd6e3660/Untitled%203.png](Ch2~Ch5%2080873313c4a1452eb69abf22fd6e3660/Untitled%203.png)

2. 다음 식을 사용하여 커널 행렬 $K$를 중앙에 맞춥니다. 

$$K' = K - 1_nK - K1_n+1_nK1_n$$

3. 고윳값 크기대로 내림차순으로 정렬하여 중앙에 맞춘 커널 행렬에서 최상위 k개의 고유벡터를 고릅니다. 표준 PCA와 다르게 고유 벡터는 주성분 축이 아니며, 이미 이 축에 투영된 샘플입니다.

여기서 두 번째 단계에서 왜 커널 행렬을 중앙에 맞추었는지에 대한 이유는 다음과 같습니다. 앞서 우리는 표준화 전처리된 데이터를 다룬다고 가정했습니다. 공분산 행렬을 구성하고 비선형 특성 조합으로 점곱을 $\phi$ 번째 단계에서 왜 커널 행렬을 중앙에 맞추었는지 궁금할지 모르겠습니다. 앞서 우리는 표준화 전처리된 데이터를 다룬다고 가정했습니다. 공분산 행렬을 구성하고 비선형 특성 조합으로 점곱을 $\phi$를 사용한 비선형 특성 조합으로 점곱을 대체할 대 사용한 모든 특성의 평균이 0입니다. 반면 새로운 특성 공간을 명시적으로 계산하지 않기 때문에 이 특성 공간이 중앙에 맞추어져있는지 보장할 수 없습니다. ﻿

```python
from scipy.spatial.distance import pdist, squareform
from scipy import exp
from scipy.linalg import eigh
import numpy as np

def rbf_kernel_pca(X, gamma, n_components):
    """
    RBF 커널 PCA 구현
    
    매개변수
    ------------------
    X: {넘파이 ndarray}, shape = [n_samples, n_features]
    
    gamma: float
     RBF 커널 튜닝 매개변수
     
    n_components: int
     반환할 주성분 개수 
     
    반환값
    ------------------
    X_pc: {넘파이 ndarray}, shape = [n_samples, n_features]
     투영된 데이터셋
     
    """
    # M x N 차원의 데이터셋에서 샘플 간의 유클리디안 거리의 제곱을 계산합니다.
    sq_dists = pdist(X, 'sqeuclidean')
    
    # 샘플 간의 거리를 정방 대칭 행렬로 변환합니다
    mat_sq_dists = squareform(sq_dists)
    
    # 커널 행렬을 계산합니다
    K = exp(-gamma * mat_sq_dists)
    
    # 커널 행렬을 중앙에 맞춥니다
    N = K.shapq[0]
    one_n = np.ones((N, N)) / N
    K = K - one_n.dot(K) - K.dot(one_n) + one_n.dot(K).dot(one_n)
    
    # 중앙에 맞춰진 커널 행렬의 고윳값과 고유 벡터를 구합니다
    # scipy.linalg.eigh 함수는 오름차순으로 반환합니다
    eigvals, eigvecs = eigh(K)
    eigvals, eigvecs = eigvals[::-1], eigvecs[:, ::-1]
    
    # 최상위 k개의 고유 벡터를 선택합니다(투영 결과)
    X_pc = np.column_stack([eigvecs[:, i] for i in range(n_components)])
    
    return X_pc
```

### 새로운 데이터 포인트 투영

훈련 데이터셋에 포함되지 않았던 새로운 데이터 포인트를 투영하는 방법을 배우겠습니다. 기본 PCA와 다르게 커널 PCA는 메모리 기반 방법입니다. 즉, 새로운 샘플을 투영하기 위해 매번 원본 훈련세트를 재사용해야 합니다. 훈련 세트에 있는 i번째 새로운 샘플과 새로운 샘플 x'사이 RBF 커널을 계산해야 합니다. 

위의 코드에서 고윳값을 반환하는 코드를 추가해주면 됩니다.

```python
    # 최상위 k개의 고유 벡터를 선택합니다(투영 결과)
    alphas = np.column_stack([eigvecs[:, i] for i in range(n_components)])
    
    # 고유 벡터에 상응하는 고윳값을 선택합니다
    lambdas = [eigvals[i] for i in range(n_components)]
    
    return alphas, lambdas
```

```python
def project_x(x_new, X, gamma, alphas, lambdas):
    pair_dist = np.array([np.sum((x_new - row)**2) for row in X])
    k = np.exp(-gamma * pair_dist)
    return k.dot(alphas / lambdas)
```